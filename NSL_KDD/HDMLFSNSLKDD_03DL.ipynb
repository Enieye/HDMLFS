{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRHmSyHxEIhN"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T02:20:28.885633Z",
     "iopub.status.busy": "2024-01-17T02:20:28.885208Z",
     "iopub.status.idle": "2024-01-17T02:20:32.051398Z",
     "shell.execute_reply": "2024-01-17T02:20:32.050564Z"
    },
    "id": "JM7hDSNClfoK"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    " \n",
    "# from tensorflow.keras import layers, regularizers\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "\n",
    "from tensorflow.keras import layers, models, callbacks, regularizers\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import KFold  # Corrected import\n",
    "\n",
    "import scipy.stats as stats\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import  sys\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "grandparent_dir = os.path.dirname(parent_dir)\n",
    "sys.path.append(grandparent_dir)\n",
    "\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "import utils \n",
    "import utils.utility as utility\n",
    "import shap\n",
    "import utils.dnn_binaryClassification as dnnbin\n",
    "import utils.dnn_multiClassification as dnnmulti\n",
    "import utils.dnn_explanations as dnnexp\n",
    "import utils.ml_utility as mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3iZVjziKHmX"
   },
   "source": [
    "## Data processing and exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'path/to/HDMLFS/data_folder/'\n",
    "datasets_full = data_dir + '01fulltraintest.csv'\n",
    "\n",
    "# Loading tdatasets into dataframe\n",
    "\n",
    "df = pd.read_csv(datasets_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing the memory usage\n",
    "from utils.reduce_memory import optimize_memory\n",
    "df = optimize_memory(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['attack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['attack', 'Threat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2l = ['ftp_write', 'xlock', 'xsnoop', 'guess_passwd', 'imap', 'named', 'warezmaster',\n",
    "       'multihop', 'sendmail', 'snmpguess', 'snmpgetattack', 'spy', 'warezclient', 'worm', 'phf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dos = ['pod', 'smurf', 'apache2', 'teardrop', 'back', 'land', \n",
    "       'mailbomb', 'neptune', 'udpstorm', 'processtable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = ['ipsweep', 'portsweep', 'mscan', 'saint', 'nmap', 'satan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u2r = ['loadmodule', 'buffer_overflow', 'perl', 'xterm', 'httptunnel', \n",
    "       'rootkit', 'ps', 'sqlattack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping dictionary for replacement\n",
    "replace_dict = {**{item: 'r2l' for item in r2l},\n",
    "                **{item: 'dos' for item in dos},\n",
    "                **{item: 'probe' for item in probe},\n",
    "                **{item: 'u2r' for item in u2r}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['attack'] = df['attack'].replace(replace_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a binary column for attack\n",
    "df = utility.getBin(df, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = list(df[label[0]].value_counts().index.sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_zero_columns = df.columns[(df == 0).all()]\n",
    "constant_zero_columns = list(constant_zero_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Removing features that have constant_zero_columns\n",
    "df = df.drop(constant_zero_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Binary columns\n",
    "\n",
    "binary_columns = [c for c\n",
    "                       in list(df.drop(labels, axis=1))\n",
    "                       if df[c].nunique() == 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['protocol_type', 'service', 'flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = list(set(df.columns) - set(categorical_columns)- set(binary_columns) - set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation\n",
    "utility.plot_correlation_heatmap_no_numbers(df[numerical_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for correlation between the numeric variables\n",
    "corr_columns = utility.find_correlated_columns(df[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keys = {key for d in corr_columns for key in d.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_corr_columns = list(all_keys)\n",
    "distinct_values = set()\n",
    "\n",
    "for d in corr_columns:\n",
    "    for value in d.values():\n",
    "        # Check if the value is a list \n",
    "        if isinstance(value, list):\n",
    "            # Add each element of the list as a separate item in the set\n",
    "            distinct_values.update(value)\n",
    "        else:\n",
    "            # Otherwise, just add the value to the set\n",
    "            distinct_values.add(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_key_values = all_keys.intersection(distinct_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric columns to be removed because of corrlation\n",
    "removed_columns = list(distinct_values - common_key_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now remove removed_columns from the df and numerical columns\n",
    "df = df.drop(removed_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns2 = list(set(numerical_columns)-set(removed_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the Categoirical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First reducing the cardinality of all the categorical features \n",
    "for feature in categorical_columns:   \n",
    "    print(f\"{feature} : {df[feature].nunique()} unique categories\")\n",
    "    if df[feature].nunique()>6:\n",
    "        df[feature] = np.where(df[feature].isin(df[feature].value_counts().head(5).index), df[feature], 'others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hot encoding the categorical data\n",
    "encoder = OneHotEncoder(sparse_output=False, dtype=np.int32, handle_unknown=\"ignore\")\n",
    "encoded_categorical_train = encoder.fit_transform(df[categorical_columns])\n",
    "\n",
    "encoded_feature_names = encoder.get_feature_names_out(categorical_columns)\n",
    "df_ohe = pd.DataFrame(encoded_categorical_train, columns=encoded_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.concat([df_ohe, df[numerical_columns2], df[binary_columns], df[labels]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, label encoding the 'attack' feature \n",
    "le = LabelEncoder()\n",
    "df_full[labels[0]] = le.fit_transform(df_full[labels[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, y_train, y_test = train_test_split(df_full.drop('set_type', axis=1), df_full[labels[0]], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_scaler = MinMaxScaler()\n",
    "train_df[numerical_columns2] = minmax_scaler.fit_transform(train_df[numerical_columns2])\n",
    "test_df[numerical_columns2] = minmax_scaler.transform(test_df[numerical_columns2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train,  X_valid, y_valid, X_test, y_test, feature_names, input_shape = dnnmulti.generateDataSet(train_df, test_df,\n",
    "                                                                                                           labels, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "report_df_dnn, history_dnn, model_dnn, y_true_dnn, y_pred_dnn = dnnmulti.trainDNNMultiClass(X_train, y_train, X_valid, y_valid, X_test, y_test, num_classes, \n",
    "                       label_names, 128, dropout_rate=0.1, l1_reg=1e-3, model_name=\"Feedforward_NN\")\n",
    "\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'DNN Metrics in 4dp: \\n: {report_df_dnn}')\n",
    "\n",
    "print(f'\\nDNN DL training takes: {(t2-t1):.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "report_df_cnn, history_cnn, model_cnn, y_true_cnn, y_pred_cnn = dnnmulti.trainCNNMultiClass(X_train, y_train, X_valid, y_valid, X_test, y_test, num_classes, \n",
    "                       label_names, batch_size=128, dropout_rate=1e-8, l1_reg=1e-8, model_name=\"CNN\")\n",
    "t2 = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'CNN Metrics in 4dp: \\n: {report_df_cnn}')\n",
    "\n",
    "print(f'\\nCNN DL training takes: {(t2-t1):.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "report_df_resnet, history_resnet, model_resnet, y_true_resnet, y_pred_resnet = dnnmulti.trainResNetMultiClass(X_train, y_train, X_valid, y_valid, X_test, y_test, num_classes, \n",
    "                          label_names, 128, dropout_rate=1e-12, l1_reg=1e-12, model_name=\"Resnet\")\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'ResNet Metrics in 4dp: \\n: {report_df_resnet}')\n",
    "\n",
    "print(f'\\nResNet DL training takes: {(t2-t1):.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnmulti.dnn_multiConfxMtrx(y_true_dnn, y_pred_dnn, label_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnmulti.dnn_multiConfxMtrx(y_true_cnn, y_pred_cnn, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnmulti.dnn_multiConfxMtrx(y_true_resnet, y_pred_resnet, label_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the feature importance \n",
    "feature_importancesDNN = dnnexp.compute_intgrd_explanations(model_dnn, X_test, feature_names, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top25IGNSLKDDFeats = list(feature_importancesDNN.Features)[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnexp.plotImportance(feature_importancesDNN[:20], figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_imp_dnn, shap_values_dnn, X_sample_dnn = dnnexp.shap_importance_multi(model_dnn, X_test, feature_names, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top25SHAPNSLKDDFeats = list(shap_imp_dnn.Features)[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnexp.create_shap_bar_multi(shap_values_dnn, X_sample_dnn, feature_names, max_display=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnexp.create_shap_waterfall_multi(shap_values_dnn, X_sample_dnn, feature_names, instance_idx=0, max_display=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnexp.create_shap_summary_aggregated(shap_values_dnn, X_sample_dnn, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnexp.create_shap_waterfall_aggregated(shap_values_dnn, X_sample_dnn, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_featuresIGShap = dnnexp.select_IGShapFeatures(feature_importancesDNN, shap_imp_dnn, thresh=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sf, y_train_sf,  X_valid_sf, y_valid_sf, X_test_sf, y_test_sf, feature_names_sf, input_shape_sf = dnnmulti.getSFDataSet(train_df, test_df,\n",
    "                                                                        selected_featuresIGShap+[labels[1]], label, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "report_df_dnn_sf, history_dnn2, model_dnn2, y_true_dnn2, y_pred_dnn2 = dnnmulti.trainDNNMultiClass(X_train_sf, y_train_sf, X_valid_sf, y_valid_sf, X_test_sf, y_test_sf, num_classes, \n",
    "                       label_names, 128, dropout_rate=1e-5, l1_reg=1e-5, model_name=\"Feedforward_NN\")\n",
    "                       \n",
    "t2 = time.time()                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'DNN_SF Metrics in 4dp: \\n: {report_df_dnn_sf}')\n",
    "\n",
    "print(f'\\nDNN_SF DL training takes: {(t2-t1):.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnmulti.dnn_multiConfxMtrx(y_true_dnn2, y_pred_dnn2, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "report_cnn_sf, history_cnn_sf, model_cnn_sf, y_true_cnn_sf, y_pred_cnn = dnnmulti.trainCNNMultiClass(X_train_sf, y_train_sf, X_valid_sf, y_valid_sf, X_test_sf, y_test_sf, \n",
    "                                                                                                     num_classes, label_names, 128, dropout_rate=1e-8, l1_reg=1e-8, model_name=\"cnn_withFS\")\n",
    "\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(f'CNN_SF Metrics in 4dp: \\n: {report_cnn_sf}')\n",
    "\n",
    "print(f'\\nCNN_SF DL training takes: {(t2-t1):.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnmulti.dnn_multiConfxMtrx(y_true_cnn_sf, y_pred_cnn, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "report_resnet_sf, history_resnet_sf, model_resnet_sf, y_true_resnet_sf, y_pred_resnet = dnnmulti.trainResNetMultiClass(X_train_sf, y_train_sf, X_valid_sf, y_valid_sf, X_test_sf, y_test_sf, num_classes, \n",
    "                                                                                                                       label_names, 128, dropout_rate=1e-8, l1_reg=1e-8, model_name=\"Resnet_withFS\")\n",
    "\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'ResNet_SF Metrics in 4dp: \\n: {report_resnet_sf}')\n",
    "\n",
    "print(f'\\nResNet_SF DL training takes: {(t2-t1):.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnmulti.dnn_multiConfxMtrx(y_true_resnet_sf, y_pred_resnet, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnmulti.plotModel(history_dnn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnmulti.plotModel(history_cnn_sf, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnmulti.plotModel(history_resnet_sf, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing Ablation Studies (abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Ablation Studies\n",
    "# i. ABS IG\n",
    "\n",
    "# Considering the top 25 encoded features from IG \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "X_train_absIG, y_train_absIG,  X_valid_absIG, y_valid_absIG, X_test_absIG, y_test_absIG, feature_names_absIG, input_shape_absIG = dnnmulti.getSFDataSet(train_df, test_df,\n",
    "                                                                        top25IGNSLKDDFeats, label, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# a. DNN ABS IG \n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "\n",
    "report_df_dnn_absIG, history_dnn_absIG, model_dnn_absIG, y_true_dnn_absIG, y_pred_dnn_absIG = dnnmulti.trainDNNMultiClass(X_train_absIG, y_train_absIG, X_valid_absIG, y_valid_absIG, X_test_absIG, y_test_absIG, num_classes, \n",
    "                       label_names, 128, dropout_rate=1e-2, l1_reg=1e-2, model_name=\"Feedforward_NNabs\")\n",
    "                       \n",
    "t2 = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                   \n",
    "print(f'DNN_IG Metrics in 4dp: \\n: {report_df_dnn_absIG}')\n",
    "\n",
    "print(f'\\nDNN_IG training takes: {(t2-t1):.2f}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "report_df_cnn_absIG, history_cnn_absIG, model_cnn_absIG, y_true_cnn_absIG, y_pred_cnn_absIG = dnnmulti.trainCNNMultiClass(X_train_absIG, y_train_absIG, X_valid_absIG, y_valid_absIG, X_test_absIG, y_test_absIG, num_classes, \n",
    "                       label_names, 128, dropout_rate=1e-2, l1_reg=1e-2, model_name=\"Feedforward_NNabs\")\n",
    "                       \n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'CNN_IG Metrics in 4dp: \\n: {report_df_cnn_absIG}')\n",
    "\n",
    "print(f'\\nCNN_IG training takes: {(t2-t1):.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c. ResNet ABS IG \n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "report_df_resnet_absIG, history_resnet_absIG, model_resnet_absIG, y_true_resnet_absIG, y_pred_resnet_absIG = dnnmulti.trainResNetMultiClass(X_train_absIG, y_train_absIG, X_valid_absIG, y_valid_absIG, X_test_absIG, y_test_absIG, num_classes, \n",
    "                       label_names, 128, dropout_rate=1e-2, l1_reg=1e-2, model_name=\"Feedforward_NNabs\")\n",
    "                       \n",
    "t2 = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'ResNet_IG Metrics in 4dp: \\n: {report_df_resnet_absIG}')\n",
    "\n",
    "print(f'\\nResNet_IG training takes: {(t2-t1):.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i. ABS SHAP\n",
    "\n",
    "# Considering the top 25 encoded features from SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_absSHAP, y_train_absSHAP,  X_valid_absSHAP, y_valid_absSHAP, X_test_absSHAP, y_test_absSHAP, feature_names_absSHAP, input_shape_absSHAP = dnnmulti.getSFDataSet(train_df, test_df,\n",
    "                                                                        top25SHAPNSLKDDFeats, label, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # b. DNN ABS SHAP\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "\n",
    "report_df_dnn_absSHAP, history_dnn_absSHAP, model_dnn_absSHAP, y_true_dnn_absSHAP, y_pred_dnn_absSHAP = dnnmulti.trainDNNMultiClass(X_train_absSHAP, y_train_absSHAP, X_valid_absSHAP, y_valid_absSHAP, X_test_absSHAP, y_test_absSHAP, num_classes, \n",
    "                       label_names, 128, dropout_rate=1e-2, l1_reg=1e-2, model_name=\"Feedforward_NNabs\")\n",
    "                       \n",
    "t2 = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'DNN_SHAP Metrics in 4dp: \\n: {report_df_dnn_absSHAP}')\n",
    "\n",
    "print(f'\\nDNN_SHAP training takes: {(t2-t1):.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. CNN ABS SHAP\n",
    "t1 = time.time()\n",
    "\n",
    "\n",
    "report_df_cnn_absSHAP, history_cnn_absSHAP, model_cnn_absSHAP, y_true_cnn_absSHAP, y_pred_cnn_absSHAP = dnnmulti.trainCNNMultiClass(X_train_absSHAP, y_train_absSHAP, X_valid_absSHAP, y_valid_absSHAP, X_test_absSHAP, y_test_absSHAP, num_classes, \n",
    "                       label_names, 128, dropout_rate=1e-2, l1_reg=1e-2, model_name=\"Feedforward_NNabs\")\n",
    "                       \n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "print(f'CNN_SHAP Metrics in 4dp: \\n: {report_df_cnn_absSHAP}')\n",
    "\n",
    "print(f'\\nCNN_SHAP training takes: {(t2-t1):.2f}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c ResNet ABS SHAP\n",
    "t1 = time.time()\n",
    "\n",
    "\n",
    "report_df_resnet_absSHAP, history_resnet_absSHAP, model_resnet_absSHAP, y_true_resnet_absSHAP, y_pred_resnet_absSHAP = dnnmulti.trainResNetMultiClass(X_train_absSHAP, y_train_absSHAP, X_valid_absSHAP, y_valid_absSHAP, X_test_absSHAP, y_test_absSHAP, num_classes, \n",
    "                       label_names, 128, dropout_rate=1e-2, l1_reg=1e-2, model_name=\"Feedforward_NNabs\")\n",
    "                       \n",
    "t2 = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'ResNet_SHAP Metrics in 4dp: \\n: {report_df_resnet_absSHAP}')\n",
    "\n",
    "print(f'\\nResNet_SHAP training takes: {(t2-t1):.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stop = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The script took a total of: {(t_stop-t_start):.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "imbalanced_data.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "venvTFGPU02122025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
